{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from database_tools.tools import BuildDatabase\n",
    "from database_tools.preprocessing.utils import build_data_directory, ConfigMapper\n",
    "\n",
    "repo_dir = '/home/cam/Documents/database_tools/'\n",
    "data_dir = build_data_directory(repo_dir + 'data/', 'mimic3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    checks=['snr', 'hr', 'beat', 'notch'],\n",
    "    fs=125,                                 # sampling frequency\n",
    "    win_len=256,                            # window length\n",
    "    freq_band=[0.5, 8.0],                   # bandpass frequencies\n",
    "    sim=0.6,                                # similarity threshold\n",
    "    snr=2.0,                                # SNR threshold\n",
    "    hr_freq_band=[0.667, 3.0],              # valid heartrate frequency band in Hz\n",
    "    hr_delta=1/6,                           # maximum heart rate difference between ppg, abp\n",
    "    dbp_bounds=[20, 130],                   # upper and lower threshold for DBP\n",
    "    sbp_bounds=[50, 225],                   # upper and lower threshold for SBP\n",
    "    flat_line_length=10,                    # max length of flat lines\n",
    "    windowsize=1,                           # windowsize for rolling mean\n",
    "    ma_perc=20,                             # multiplier for peak detection\n",
    "    beat_sim=0.2,                           # lower threshold for beat similarity\n",
    "    min_notches=1,                          # minimum number of dichrotic notches in a window\n",
    ")\n",
    "\n",
    "cm = ConfigMapper(config=config)\n",
    "\n",
    "bd = BuildDatabase(\n",
    "    data_dir=data_dir,\n",
    "    samples_per_file=100,\n",
    "    samples_per_patient=50,\n",
    "    max_samples=100,\n",
    ")\n",
    "\n",
    "bd.run(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 200\n",
    "\n",
    "stats = pd.read_csv(data_dir + 'mimic3_stats.csv')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(data_dir + 'data/lines/mimic3_000.jsonlines', lines=True)\n",
    "\n",
    "ppg = np.array(data['ppg'].to_list())\n",
    "abp = np.array(data['abp'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget()\n",
    "fig.add_scatter(y=ppg[99, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from database_tools.tools.records import Dataset, get_split_idx, split_data\n",
    "\n",
    "dt = 20230220\n",
    "data_dir = f'/home/cam/Documents/database_tools/data/mimic3-data-{dt}/data/'\n",
    "\n",
    "ds = Dataset(data_dir=data_dir)\n",
    "idx = get_split_idx(n=ds.ppg.shape[0], split_strategy=(0.7, 0.15, 0.15))\n",
    "data_unscaled = split_data(ds, idx)\n",
    "\n",
    "data_scaled = {'ppg': {}, 'vpg': {}, 'apg': {}, 'abp': {}}\n",
    "train_scaler = {}\n",
    "test_scaler = {}\n",
    "\n",
    "for key in ['ppg', 'vpg', 'apg', 'abp']:\n",
    "    min_ = np.min(data_unscaled[key]['train'])\n",
    "    max_ = np.max(data_unscaled[key]['train'])\n",
    "\n",
    "    train_scaler[key] = [min_, max_]\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        tmp = data_unscaled[key][split]\n",
    "        tmp_scaled = np.divide(tmp - min_, max_ - min_)\n",
    "        data_scaled[key][split] = tmp_scaled\n",
    "\n",
    "for key in ['ppg', 'vpg', 'apg', 'abp']:\n",
    "    min_ = np.min(data_unscaled[key]['test'])\n",
    "    max_ = np.max(data_unscaled[key]['test'])\n",
    "\n",
    "    test_scaler[key] = [min_, max_]\n",
    "\n",
    "    for split in ['test']:\n",
    "        tmp = data_unscaled[key][split]\n",
    "        tmp_scaled = np.divide(tmp - min_, max_ - min_)\n",
    "        data_scaled[key][split] = tmp_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "fig.add_scatter(y=data_scaled['ppg']['train'][0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heartfelt-tools-Qo_l_FwJ-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11be1819121c33cfc84416af11ffbdbeaf074b50fda951b7acc91346a1aaeb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
