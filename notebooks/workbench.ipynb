{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from database_tools.tools import BuildDatabase\n",
    "\n",
    "repo_dir = '/home/cam/Documents/database_tools/'\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "config = dict(\n",
    "    low=0.5,                    # low bandpass frequency\n",
    "    high=8.0,                   # high bandpass frequency\n",
    "    sim=0.6,                    # similarity threshold\n",
    "    df=0.2,                     # one sided frequency delta for SNR calculation\n",
    "    snr_t=2.0,                  # SNR threshold\n",
    "    hr_diff=1/6,                # maximum heart rate difference between ppg, abp\n",
    "    f0_low=0.667,               # minimum valid HR in Hz\n",
    "    f0_high=3.0,                # maximum valid HR in Hz\n",
    "    abp_min_bounds=[40, 110],   # upper and lower threshold for DBP\n",
    "    abp_max_bounds=[70, 190],   # upper and lower threshold for SBP\n",
    "    pp_min=25,                  # pulse pressure lower threshold\n",
    "    pp_max=75,                  # pulse pressure upper threshold\n",
    "    n_peaks=2,                  # minimum number of peaks in a window\n",
    "    windowsize=1,               # windowsize for rolling mean\n",
    "    ma_perc=20,                 # multiplier for peak detection\n",
    "    beat_sim=0.2,               # lower threshold for beat similarity\n",
    ")\n",
    "\n",
    "worker = BuildDatabase(\n",
    "    output_dir='data-2022-11-08/',\n",
    "    config=config,\n",
    "    win_len=256,\n",
    "    fs=125,\n",
    "    samples_per_file=2500,\n",
    "    max_samples=200000,\n",
    "    data_dir='physionet.org/files/mimic3wdb/1.0/',\n",
    ")\n",
    "\n",
    "worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data-2022-11-08/mimic3_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half = math.floor(len(df) / 2)\n",
    "df1 = df.iloc[0:half]\n",
    "df2 = df.iloc[half::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('../data-2022-11-08/valid_segs_1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from database_tools.tools import DataEvaluator\n",
    "\n",
    "repo_dir = '/home/cam/Documents/database_tools/'\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "pd.options.display.max_rows = 2500\n",
    "\n",
    "df = pd.read_csv('data-2022-11-08/mimic3_stats.csv')\n",
    "worker = DataEvaluator(stats=df)\n",
    "\n",
    "figs = worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from heartpy.preprocessing import flip_signal\n",
    "from heartpy.peakdetection import detect_peaks\n",
    "from heartpy.datautils import rolling_mean\n",
    "from database_tools.preprocessing.SignalLevelFiltering import get_similarity\n",
    "\n",
    "def make_equal_len(x, y):\n",
    "    len_x = len(x)\n",
    "    len_y = len(y)\n",
    "    if len_x > len_y:\n",
    "        y = np.pad(y, pad_width=[0, len_x - len_y])\n",
    "    else:\n",
    "        x = np.pad(x, pad_width=[0, len_y - len_x])\n",
    "    return x, y\n",
    "\n",
    "def beat_similarity(x, windowsize, ma_perc, fs=125):\n",
    "    x_pad = np.pad(x, pad_width=[9, 9])\n",
    "    rol_mean = rolling_mean(x_pad, windowsize=windowsize, sample_rate=fs)\n",
    "    peaks = detect_peaks(x_pad, rol_mean, ma_perc=ma_perc, sample_rate=fs)['peaklist']\n",
    "    peaks = np.array(peaks) - 10\n",
    "    flip = flip_signal(x_pad)\n",
    "    rol_mean = rolling_mean(flip, windowsize=windowsize, sample_rate=fs)\n",
    "    valleys = detect_peaks(flip, rol_mean, ma_perc=ma_perc, sample_rate=fs)['peaklist']\n",
    "    valleys = np.array(valleys) - 10\n",
    "\n",
    "    # check no peaks are valleys\n",
    "    if np.isin(peaks, valleys).any():\n",
    "        return [-2, -1]\n",
    "\n",
    "    # check that peaks and valleys are in order\n",
    "    hist = np.digitize(valleys, peaks)\n",
    "    if not np.array([hist[i] == hist[i+1] - 1 for i in range(len(hist) - 1)]).all():\n",
    "        return [-3, -1]\n",
    "\n",
    "    neg_len = lambda x : len(x) * -1\n",
    "    if len(peaks) <= len(valleys):\n",
    "        beats = sorted(np.split(x, valleys), key=neg_len)\n",
    "\n",
    "        aligned_beats = [beats[0]]\n",
    "\n",
    "        for i, b in enumerate(beats[1::]):\n",
    "            b_new = np.pad(b, pad_width=[len(beats[0]) - len(b), 0])\n",
    "            aligned_beats.append(b_new)\n",
    "    else:\n",
    "        beats = sorted(np.split(x, valleys[1::]), key=neg_len)\n",
    "\n",
    "        aligned_beats = [beats[0]]\n",
    "\n",
    "        for i, b in enumerate(beats[1::]):\n",
    "            b_new = np.pad(b, pad_width=[peaks[0] - (peaks[i + 1] - valleys[i]), 0])\n",
    "            aligned_beats.append(b_new)\n",
    "\n",
    "    aligned_beats = [b for b in aligned_beats if len(b[b != 0]) > fs / 2]\n",
    "    idx = [(i, j) for ((i, _), (j, _)) in itertools.combinations(enumerate([i for i in range(len(aligned_beats))]), 2)]\n",
    "\n",
    "    s = 0\n",
    "    for i, j in idx:\n",
    "        x, y = make_equal_len(aligned_beats[i], aligned_beats[j])\n",
    "        s += get_similarity(x, y)\n",
    "    try:\n",
    "        return [s / len(aligned_beats), len(aligned_beats)]\n",
    "    except ZeroDivisionError:\n",
    "        return [-4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "repo_dir = '/home/cam/Documents/database_tools/'\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "# for ppg (windowsize=2, ma_perc=20)\n",
    "# for abp (windowsize=2, ma_perc=1)\n",
    "\n",
    "stats = []\n",
    "for i in tqdm(range(0, 120), total=120):\n",
    "    ppg = []\n",
    "    abp = []\n",
    "    with open(f'data-2022-11-08/mimic3/lines/mimic3_0000{str(i).zfill(3)}.jsonlines', 'r') as f:\n",
    "        for sample in f:\n",
    "            sample = json.loads(sample)\n",
    "            ppg.append(sample['ppg'])\n",
    "    ppg = np.array(ppg)\n",
    "    stats += [beat_similarity(x, windowsize=2, ma_perc=1) for x in ppg]\n",
    "    if i == 0:\n",
    "        break\n",
    "\n",
    "stats = np.array(stats)\n",
    "sim = stats[:, 0]\n",
    "n_beats = stats[:, 1]\n",
    "pd.Series(sim).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(pd.Series(sim).head(2500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sig = []\n",
    "with open(f'../data-2022-11-08/mimic3/lines/mimic3_0000000.jsonlines', 'r') as f:\n",
    "    for sample in f:\n",
    "        sample = json.loads(sample)\n",
    "        sig.append(sample['abp'])\n",
    "sig = np.array(sig)\n",
    "\n",
    "x = sig[2, :]\n",
    "\n",
    "pad_width = 19\n",
    "x_pad = np.pad(x, pad_width=[pad_width, 0], constant_values=[x[0]])\n",
    "x_pad = np.pad(x_pad, pad_width=[0, pad_width], constant_values=[x[-1]])\n",
    "\n",
    "fs=125\n",
    "rol_mean = rolling_mean(x_pad, windowsize=1, sample_rate=fs)\n",
    "peaks = detect_peaks(x_pad, rol_mean, ma_perc=20, sample_rate=fs)['peaklist']\n",
    "peaks = np.array(peaks) - pad_width - 1\n",
    "flip = flip_signal(x_pad)\n",
    "rol_mean = rolling_mean(flip, windowsize=1, sample_rate=fs)\n",
    "valleys = detect_peaks(flip, rol_mean, ma_perc=20, sample_rate=fs)['peaklist']\n",
    "valleys = np.array(valleys) - pad_width - 1\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.add_scatter(\n",
    "    y=x,\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=peaks,\n",
    "    y=x[peaks],\n",
    "    mode='markers',\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=valleys,\n",
    "    y=x[valleys],\n",
    "    mode='markers',\n",
    ")\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('database-tools-Qo_l_FwJ-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c826fe4c3072c6c8679b0c2c5bfc4e59fc902350ea20ac6cce5df13884cb183b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
