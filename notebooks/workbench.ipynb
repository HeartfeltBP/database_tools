{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from database_tools.io.wfdb import generate_record_paths, get_data_record, get_header_record, header_has_signals, get_signal\n",
    "from database_tools.datastores.signals import SignalStore, SignalGroup\n",
    "from database_tools.datastores.records import WaveformRecord\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "# pd.options.display.max_rows = 100\n",
    "# pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_tools.tools.dataset import ConfigMapper\n",
    "\n",
    "cm = ConfigMapper('/home/cam/Documents/database_tools/data/mimic3-data-20230407/config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "x = json.dumps(dict(ppg=[0, 1, 2], abp=[3, 4, 5])) + '\\n'\n",
    "x += json.dumps(dict(ppg=[6, 7, 8], abp=[9, 10, 11])) + '\\n'\n",
    "'\\n' in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "signals = ['PLETH', 'ABP']\n",
    "min_length = 75000  # 10 min in samples (125 Hz)\n",
    "n_segments = 50\n",
    "\n",
    "valid_segs = []\n",
    "with alive_bar(total=n_segments, bar='brackets', force_tty=True) as bar:\n",
    "    for path in ['31/3162326']:\n",
    "\n",
    "        # get patient layout header\n",
    "        layout = get_header_record(path=path, record_type='layout')\n",
    "        if layout is None: continue  # fx returns None if file DNE\n",
    "\n",
    "        # check if header has provided signals\n",
    "        if not header_has_signals(layout, signals): continue\n",
    "\n",
    "        # get patient master header\n",
    "        master = get_header_record(path=path, record_type='data')\n",
    "        if master is None: continue\n",
    "\n",
    "        # zip segment names and lengths\n",
    "        for seg_name, n_samples in zip(master.seg_name, master.seg_len):\n",
    "        \n",
    "            # check segment length\n",
    "            if (n_samples > min_length) & (seg_name != '~'):  # '~' indicates data is missing\n",
    "                seg_path = path + '/' + seg_name\n",
    "\n",
    "                # Get segment header\n",
    "                hea = get_header_record(path=seg_path, record_type='data')\n",
    "                if hea is None: continue\n",
    "\n",
    "                # Check if segment has provided signals and append\n",
    "                if header_has_signals(hea, signals):\n",
    "                    valid_segs.append(seg_path)\n",
    "                    if len(valid_segs) > n_segments:\n",
    "                        break\n",
    "                    bar()  # iterate loading bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ppg, abp = [], []\n",
    "for seg in tqdm(valid_segs[0:5]):\n",
    "    rec = get_data_record(path=seg, record_type='waveforms')\n",
    "    p = get_signal(rec, sig='PLETH')\n",
    "    a = get_signal(rec, sig='ABP')\n",
    "    ppg.append(p)\n",
    "    abp.append(a)\n",
    "ppg = np.array(ppg)\n",
    "abp = np.array(abp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_scatter(y=ppg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurokit2.ppg.ppg_findpeaks import _ppg_findpeaks_bishop\n",
    "\n",
    "def find_peaks(sig, show=False, **kwargs):\n",
    "   \"\"\"Modified version of neuroki2 ppg_findpeaks method. Returns peaks and troughs\n",
    "      instead of just peaks. See neurokit2 documentation for original function.\n",
    "   \"\"\"\n",
    "   peaks, troughs = _ppg_findpeaks_bishop(sig, show=show, **kwargs)\n",
    "   return dict(peaks=peaks[0], troughs=troughs[0])\n",
    "\n",
    "def detect_notches(sig: np.ndarray, peaks: np.ndarray, troughs: np.ndarray, dx: int = 10) -> list:\n",
    "   \"\"\"Detect dichrotic notch by find the maximum velocity\n",
    "      at least 10 samples after peak and 30 samples before\n",
    "      the subsequent trough.\n",
    "\n",
    "   Args:\n",
    "         sig (np.ndarray): Cardiac signal.\n",
    "         peaks (list): List of signal peak indices.\n",
    "         troughs (list): List of signal trough indices.\n",
    "         dx (int, optional): Spacing between sig values (for np.gradient). Defaults to 10.\n",
    "\n",
    "   Returns:\n",
    "         notches (list): List of dichrotic notch indices.\n",
    "   \"\"\"\n",
    "   # always start with first peak\n",
    "   try:\n",
    "       if peaks[0] > troughs[0]:\n",
    "           troughs = troughs[1::]\n",
    "   except IndexError:\n",
    "       return []\n",
    "\n",
    "   notches = []\n",
    "   for i, j in zip(peaks, troughs):\n",
    "       try:\n",
    "           vel = np.gradient(sig[i:j], dx)\n",
    "           vel_len = vel.shape[0]\n",
    "           n = np.argmax(vel[int(vel_len / 100 * 25):int(vel_len / 100 * 75)])\n",
    "           notches.append(n + i)  # add first index of slice to get correct notch index\n",
    "       except ValueError:  # gradient fails if slice of sig is too small\n",
    "           continue\n",
    "\n",
    "   # look for a notch after the last peak if the highest index is a peak.\n",
    "   try:\n",
    "       if peaks[-1] > troughs[-1]:\n",
    "           try:\n",
    "               vel = np.gradient(sig[peaks[-1]::], dx)\n",
    "               vel_len = vel.shape[0]\n",
    "               n = np.argmax(vel[int(vel_len / 100 * 25):int(vel_len / 100 * 75)])\n",
    "               notches.append(n + peaks[-1])\n",
    "           except ValueError:\n",
    "               pass\n",
    "   except IndexError:\n",
    "       pass\n",
    "\n",
    "   # remove notches that are just peaks\n",
    "   notches = np.array(notches)[notches - ]\n",
    "   return notches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notches = np.array([125, 300, 390, 450, 500])\n",
    "peaks = np.array([120, 290, 315, 400, 510])\n",
    "a, b = np.meshgrid(notches, peaks)\n",
    "y = b - a\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notches[np.array(np.where(np.abs(y) <= 10))[1, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = (0, 232000, 234000)\n",
    "\n",
    "x = ppg[i[0]][i[1]:i[2]]\n",
    "peaks, troughs = find_peaks(x).values()\n",
    "notches = detect_notches(x, peaks, troughs)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(y=x)\n",
    "fig.add_scatter(x=peaks, y=x[peaks], mode='markers')\n",
    "fig.add_scatter(x=troughs, y=x[troughs], mode='markers')\n",
    "fig.add_scatter(x=notches, y=x[notches], mode='markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_scatter(y=abp[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heartfelt-tools-Qo_l_FwJ-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11be1819121c33cfc84416af11ffbdbeaf074b50fda951b7acc91346a1aaeb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
